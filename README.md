# Cross-Modal-Video-Intelligence-System-Integrating-Audio-and-Vision---Youtube-Enhancement

## Resources

- 📄 [Demo Video](https://drive.google.com/file/d/1nP43fF-41fwQnVr5UtX_QmWKA9emL---/view?pli=1) from Google Drive

## 🎯 Project Summary

This project presents an **AI-powered system for intelligent YouTube video analysis and enhancement**, designed to help users extract and understand key insights from large volumes of video content. It integrates state-of-the-art models and tools across **Natural Language Processing**, **Computer Vision**, and **Video Enhancement**.

### 🚀 Key Features

- 🎙️ **Speech Transcription**  
  Utilizes OpenAI's Whisper model for accurate, multilingual transcription of video audio.

- 🧠 **Named Entity Recognition**  
  Uses spaCy to extract important entities like people, organizations, and locations from transcripts.

- 🔍 **Semantic Matching**  
  Applies BERT embeddings and cosine similarity to rank videos by relevance to user queries.

- ✂️ **Abstractive Summarization**  
  Leverages the BART model to generate concise and coherent summaries of long transcripts.

- 🧩 **Cognitive Graph Visualization**  
  Constructs and displays a semantic relationship graph using NetworkX and Matplotlib.

- 🕵️ **Object Detection**  
  Implements YOLOv9 for real-time object detection in video frames.

- 🎞️ **Video Enhancement**  
  Uses Real-ESRGAN to upscale and enhance the visual quality of video frames.

### 📚 Use Cases

Ideal for:
- Educational content summarization
- Automated content analysis
- Knowledge discovery and research
- Enhanced accessibility in media platforms

### 🛠️ Technologies Used

- Python, Flask
- Whisper, spaCy, BERT, BART, YOLOv9, Real-ESRGAN
- yt_dlp, NetworkX, Matplotlib, YouTube API

